diff --git a/base/sampling_heap_profiler/poisson_allocation_sampler.cc b/base/sampling_heap_profiler/poisson_allocation_sampler.cc
index 73929573c5ffc..36c8ae17e9d3c 100644
--- a/base/sampling_heap_profiler/poisson_allocation_sampler.cc
+++ b/base/sampling_heap_profiler/poisson_allocation_sampler.cc
@@ -12,7 +12,6 @@
 #include <utility>
 
 #include "base/allocator/dispatcher/reentry_guard.h"
-#include "base/allocator/dispatcher/tls.h"
 #include "base/check.h"
 #include "base/compiler_specific.h"
 #include "base/feature_list.h"
@@ -28,8 +27,48 @@ using ::base::allocator::dispatcher::ReentryGuard;
 
 const size_t kDefaultSamplingIntervalBytes = 128 * 1024;
 
+// Notes on TLS usage:
+//
+// * There's no safe way to use TLS in malloc() as both C++ thread_local and
+//   pthread do not pose any guarantees on whether they allocate or not.
+// * We think that we can safely use thread_local w/o re-entrancy guard because
+//   the compiler will use "tls static access model" for static builds of
+//   Chrome [https://www.uclibc.org/docs/tls.pdf].
+//   But there's no guarantee that this will stay true, and in practice
+//   it seems to have problems on macOS/Android. These platforms do allocate
+//   on the very first access to a thread_local on each thread.
+// * Directly using/warming-up platform TLS seems to work on all platforms,
+//   but is also not guaranteed to stay true. We make use of it for reentrancy
+//   guards on macOS/Android.
+// * We cannot use Windows Tls[GS]etValue API as it modifies the result of
+//   GetLastError.
+//
+// Android thread_local seems to be using __emutls_get_address from libgcc:
+// https://github.com/gcc-mirror/gcc/blob/master/libgcc/emutls.c
+// macOS version is based on _tlv_get_addr from dyld:
+// https://opensource.apple.com/source/dyld/dyld-635.2/src/threadLocalHelpers.s.auto.html
+
+// The guard protects against reentering on platforms other the macOS and
+// Android.
+thread_local bool g_tls_internal_reentry_guard = false;
+
+// Accumulated bytes towards sample thread local key.
+thread_local intptr_t g_tls_accumulated_bytes = 0;
+
+// Used as a workaround to avoid bias from muted samples. See
+// ScopedMuteThreadSamples for more details.
+thread_local intptr_t g_tls_accumulated_bytes_snapshot = 0;
 const intptr_t kAccumulatedBytesOffset = 1 << 29;
 
+// A boolean used to distinguish first allocation on a thread:
+//   false - first allocation on the thread;
+//   true  - otherwise.
+// Since g_tls_accumulated_bytes is initialized with zero the very first
+// allocation on a thread would always trigger the sample, thus skewing the
+// profile towards such allocations. To mitigate that we use the flag to
+// ensure the first allocation is properly accounted.
+thread_local bool g_tls_sampling_interval_initialized = false;
+
 // Controls if sample intervals should not be randomized. Used for testing.
 bool g_deterministic = false;
 
@@ -53,89 +92,31 @@ void (*g_hooks_install_callback)() = nullptr;
 
 // Sampling interval parameter, the mean value for intervals between samples.
 constinit std::atomic_size_t g_sampling_interval{kDefaultSamplingIntervalBytes};
-
-struct ThreadLocalData {
-  // Accumulated bytes towards sample.
-  intptr_t accumulated_bytes = 0;
-  // Used as a workaround to avoid bias from muted samples. See
-  // ScopedMuteThreadSamples for more details.
-  intptr_t accumulated_bytes_snapshot = 0;
-  // PoissonAllocationSampler performs allocations while handling a
-  // notification. The guard protects against recursions originating from these.
-  bool internal_reentry_guard = false;
-  // A boolean used to distinguish first allocation on a thread:
-  //   false - first allocation on the thread;
-  //   true  - otherwise.
-  // Since accumulated_bytes is initialized with zero the very first
-  // allocation on a thread would always trigger the sample, thus skewing the
-  // profile towards such allocations. To mitigate that we use the flag to
-  // ensure the first allocation is properly accounted.
-  bool sampling_interval_initialized = false;
-};
-
-// Returns an object storing thread-local state. This does NOT use
-// base::ThreadLocalStorage, so it's safe to call from hooks in the
-// base::ThreadLocalStorage implementation.
-ThreadLocalData* GetThreadLocalData() {
-#if USE_LOCAL_TLS_EMULATION()
-  // If available, use ThreadLocalStorage to bypass dependencies introduced by
-  // Clang's implementation of thread_local.
-  static base::NoDestructor<
-      base::allocator::dispatcher::ThreadLocalStorage<ThreadLocalData>>
-      thread_local_data("poisson_allocation_sampler");
-  return thread_local_data->GetThreadLocalData();
-#else
-  // Notes on TLS usage:
-  //
-  // * There's no safe way to use TLS in malloc() as both C++ thread_local and
-  //   pthread do not pose any guarantees on whether they allocate or not.
-  // * We think that we can safely use thread_local w/o re-entrancy guard
-  //   because the compiler will use "tls static access model" for static builds
-  //   of Chrome [https://www.uclibc.org/docs/tls.pdf].
-  //   But there's no guarantee that this will stay true, and in practice
-  //   it seems to have problems on macOS/Android. These platforms do allocate
-  //   on the very first access to a thread_local on each thread.
-  // * Directly using/warming-up platform TLS seems to work on all platforms,
-  //   but is also not guaranteed to stay true. We make use of it for reentrancy
-  //   guards on macOS/Android.
-  // * We cannot use Windows Tls[GS]etValue API as it modifies the result of
-  //   GetLastError.
-  //
-  // Android thread_local seems to be using __emutls_get_address from libgcc:
-  // https://github.com/gcc-mirror/gcc/blob/master/libgcc/emutls.c
-  // macOS version is based on _tlv_get_addr from dyld:
-  // https://opensource.apple.com/source/dyld/dyld-635.2/src/threadLocalHelpers.s.auto.html
-  thread_local ThreadLocalData thread_local_data;
-  return &thread_local_data;
-#endif
-}
-
 }  // namespace
 
 PoissonAllocationSamplerStats::PoissonAllocationSamplerStats(
     size_t address_cache_hits,
     size_t address_cache_misses,
     size_t address_cache_max_size,
     float address_cache_max_load_factor,
     AddressCacheBucketStats address_cache_bucket_stats)
     : address_cache_hits(address_cache_hits),
       address_cache_misses(address_cache_misses),
       address_cache_max_size(address_cache_max_size),
       address_cache_max_load_factor(address_cache_max_load_factor),
       address_cache_bucket_stats(std::move(address_cache_bucket_stats)) {}
 
 PoissonAllocationSamplerStats::~PoissonAllocationSamplerStats() = default;
 
 PoissonAllocationSamplerStats::PoissonAllocationSamplerStats(
     const PoissonAllocationSamplerStats&) = default;
 
 PoissonAllocationSamplerStats& PoissonAllocationSamplerStats::operator=(
     const PoissonAllocationSamplerStats&) = default;
 
 PoissonAllocationSampler::ScopedMuteThreadSamples::ScopedMuteThreadSamples() {
-  ThreadLocalData* const thread_local_data = GetThreadLocalData();
-
-  was_muted_ = std::exchange(thread_local_data->internal_reentry_guard, true);
+  was_muted_ = g_tls_internal_reentry_guard;
+  g_tls_internal_reentry_guard = true;
 
   // We mute thread samples immediately after taking a sample, which is when we
   // reset g_tls_accumulated_bytes. This breaks the random sampling requirement
@@ -125,37 +108,32 @@ PoissonAllocationSampler::ScopedMuteThreadSamples::ScopedMuteThreadSamples() {
   // amount to lower the probability that a sample is taken to close to 0. Then
   // we reset it after we're done muting thread samples.
   if (!was_muted_) {
-  thread_local_data->accumulated_bytes_snapshot =
-      thread_local_data->accumulated_bytes;
-  thread_local_data->accumulated_bytes -= kAccumulatedBytesOffset;
+  g_tls_accumulated_bytes_snapshot = g_tls_accumulated_bytes;
+  g_tls_accumulated_bytes -= kAccumulatedBytesOffset;
   }
 }
 
 PoissonAllocationSampler::ScopedMuteThreadSamples::~ScopedMuteThreadSamples() {
-  ThreadLocalData* const thread_local_data = GetThreadLocalData();
-  DCHECK(thread_local_data->internal_reentry_guard);
-  thread_local_data->internal_reentry_guard = was_muted_;
+  DCHECK(g_tls_internal_reentry_guard);
+  g_tls_internal_reentry_guard = was_muted_;
   if (!was_muted_) {
-  thread_local_data->accumulated_bytes =
-      thread_local_data->accumulated_bytes_snapshot;
+  g_tls_accumulated_bytes = g_tls_accumulated_bytes_snapshot;
   }
 }
 
 // static
 bool PoissonAllocationSampler::ScopedMuteThreadSamples::IsMuted() {
-  ThreadLocalData* const thread_local_data = GetThreadLocalData();
-  return thread_local_data->internal_reentry_guard;
+  return g_tls_internal_reentry_guard;
 }
 
 PoissonAllocationSampler::ScopedSuppressRandomnessForTesting::
     ScopedSuppressRandomnessForTesting() {
   DCHECK(!g_deterministic);
   g_deterministic = true;
-  // The accumulated_bytes may contain a random value from previous
+  // The g_tls_accumulated_bytes may contain a random value from previous
   // test runs, which would make the behaviour of the next call to
   // RecordAlloc unpredictable.
-  ThreadLocalData* const thread_local_data = GetThreadLocalData();
-  thread_local_data->accumulated_bytes = 0;
+  g_tls_accumulated_bytes = 0;
 }
 
 PoissonAllocationSampler::ScopedSuppressRandomnessForTesting::
@@ -184,16 +162,14 @@ PoissonAllocationSampler::ScopedMuteHookedSamplesForTesting::
   SetProfilingStateFlag(ProfilingStateFlag::kHookedSamplesMutedForTesting);
 
   // Reset the accumulated bytes to 0 on this thread.
-  ThreadLocalData* const thread_local_data = GetThreadLocalData();
-  accumulated_bytes_snapshot_ = thread_local_data->accumulated_bytes;
-  thread_local_data->accumulated_bytes = 0;
+  accumulated_bytes_snapshot_ = g_tls_accumulated_bytes;
+  g_tls_accumulated_bytes = 0;
 }
 
 PoissonAllocationSampler::ScopedMuteHookedSamplesForTesting::
     ~ScopedMuteHookedSamplesForTesting() {
   // Restore the accumulated bytes.
-  ThreadLocalData* const thread_local_data = GetThreadLocalData();
-  thread_local_data->accumulated_bytes = accumulated_bytes_snapshot_;
+  g_tls_accumulated_bytes = accumulated_bytes_snapshot_;
   ResetProfilingStateFlag(ProfilingStateFlag::kHookedSamplesMutedForTesting);
 }
 
@@ -299,10 +275,8 @@ void PoissonAllocationSampler::RecordAlloc(void* address,
     size_t size,
     base::allocator::dispatcher::AllocationSubsystem type,
     const char* context) {
-  ThreadLocalData* const thread_local_data = GetThreadLocalData();
-
-  thread_local_data->accumulated_bytes += size;
-  intptr_t accumulated_bytes = thread_local_data->accumulated_bytes;
+  g_tls_accumulated_bytes += size;
+  intptr_t accumulated_bytes = g_tls_accumulated_bytes;
   if (accumulated_bytes < 0) [[likely]] {
     return;
   }
@@ -310,8 +284,8 @@ void PoissonAllocationSampler::RecordAlloc(void* address,
     // rare state when the sampler is stopped after it's started. (The most
     // common caller of PoissonAllocationSampler starts it and leaves it running
     // for the rest of the Chrome session.)
-    thread_local_data->sampling_interval_initialized = false;
-    thread_local_data->accumulated_bytes = 0;
+    g_tls_sampling_interval_initialized = false;
+    g_tls_accumulated_bytes = 0;
     return;
   }
 
@@ -327,16 +301,16 @@ void PoissonAllocationSampler::DoRecordAlloc(intptr_t accumulated_bytes,
   }
 
   size_t mean_interval = g_sampling_interval.load(std::memory_order_relaxed);
-  if (!thread_local_data->sampling_interval_initialized) [[unlikely]] {
-    thread_local_data->sampling_interval_initialized = true;
+  if (!g_tls_sampling_interval_initialized) [[unlikely]] {
+    g_tls_sampling_interval_initialized = true;
     // This is the very first allocation on the thread. It always makes it
     // passing the condition at |RecordAlloc|, because accumulated_bytes
     // is initialized with zero due to TLS semantics.
     // Generate proper sampling interval instance and make sure the allocation
     // has indeed crossed the threshold before counting it as a sample.
     accumulated_bytes -= GetNextSampleInterval(mean_interval);
     if (accumulated_bytes < 0) {
-      thread_local_data->accumulated_bytes = accumulated_bytes;
+      g_tls_accumulated_bytes = accumulated_bytes;
       return;
     }
   }
@@ -353,7 +326,7 @@ void PoissonAllocationSampler::DoRecordAlloc(intptr_t accumulated_bytes,
     ++samples;
   } while (accumulated_bytes >= 0);
 
-  thread_local_data->accumulated_bytes = accumulated_bytes;
+  g_tls_accumulated_bytes = accumulated_bytes;
 
   if (ScopedMuteThreadSamples::IsMuted()) [[unlikely]] {
     return;
@@ -410,7 +417,7 @@ PoissonAllocationSampler* PoissonAllocationSampler::Get() {
 
 // static
 intptr_t PoissonAllocationSampler::GetAccumulatedBytesForTesting() {
-  return GetThreadLocalData()->accumulated_bytes;
+  return g_tls_accumulated_bytes;
 }
 
 // static
